# Chapter 7: æŒ‡ä»¤å¾®è°ƒ

æœ¬ç« ä»‹ç»å¦‚ä½•å¯¹ GPT æ¨¡å‹è¿›è¡ŒæŒ‡ä»¤å¾®è°ƒ (Instruction Fine-tuning)ï¼Œä½¿å…¶èƒ½å¤Ÿéµå¾ªç”¨æˆ·æŒ‡ä»¤å®Œæˆå„ç§ä»»åŠ¡ã€‚

---

## ğŸ“‚ æ–‡ä»¶è¯´æ˜

```
chap7-fine-tuning-to-follow-instruction/
â”œâ”€â”€ fine-tuning.py                                      # ä¸»å¾®è°ƒè„šæœ¬
â”œâ”€â”€ gpt_instruction_finetuning.py                       # æŒ‡ä»¤å¾®è°ƒå®ç°
â”œâ”€â”€ prepare_dataset.py                                  # æ•°æ®é›†å‡†å¤‡
â”œâ”€â”€ create_data_loaders.py                              # æ•°æ®åŠ è½½å™¨
â”œâ”€â”€ organize_data.py                                    # æ•°æ®ç»„ç»‡
â”œâ”€â”€ evaluate_model.py                                   # æ¨¡å‹è¯„ä¼°
â”œâ”€â”€ extract_response.py                                 # æå–æ¨¡å‹å“åº”
â”œâ”€â”€ load_weights.py                                     # åŠ è½½æƒé‡
â”œâ”€â”€ gpt_download.py                                     # ä¸‹è½½ GPT-2
â”œâ”€â”€ previous_chapters.py                                # å‰å‡ ç« ä»£ç 
â”œâ”€â”€ instruction-data.json                               # æŒ‡ä»¤æ•°æ®é›†
â”œâ”€â”€ instruction-data-full.json                          # å®Œæ•´æŒ‡ä»¤æ•°æ®
â”œâ”€â”€ instruction-data-with-response_gpt2-medium_355M.json # å¸¦å“åº”çš„æ•°æ®
â”œâ”€â”€ gpt2-medium355M-sft.pth                            # å¾®è°ƒåæ¨¡å‹
â”œâ”€â”€ loss-plot.pdf                                       # æŸå¤±æ›²çº¿
â””â”€â”€ gpt2/                                               # GPT-2 é¢„è®­ç»ƒæ¨¡å‹
```

---

## ğŸ¯ å­¦ä¹ ç›®æ ‡

- âœ… ç†è§£æŒ‡ä»¤å¾®è°ƒ (Instruction Tuning)
- âœ… å‡†å¤‡æŒ‡ä»¤æ•°æ®é›†æ ¼å¼
- âœ… å®ç°ç›‘ç£å¼å¾®è°ƒ (SFT)
- âœ… è¯„ä¼°æŒ‡ä»¤éµå¾ªèƒ½åŠ›
- âœ… æŒæ¡æç¤ºå·¥ç¨‹ (Prompt Engineering)

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å‡†å¤‡æŒ‡ä»¤æ•°æ®é›†

```bash
python prepare_dataset.py
```

**æŒ‡ä»¤æ•°æ®æ ¼å¼**:
```json
[
    {
        "instruction": "å°†ä»¥ä¸‹å¥å­ç¿»è¯‘æˆæ³•è¯­",
        "input": "Hello, how are you?",
        "output": "Bonjour, comment allez-vous?"
    },
    {
        "instruction": "æ€»ç»“ä»¥ä¸‹æ–‡æœ¬",
        "input": "é•¿æ–‡æœ¬...",
        "output": "æ‘˜è¦..."
    }
]
```

### 2. ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹

```bash
python gpt_download.py --model gpt2-medium
```

ä¸‹è½½ GPT-2 Medium (355M) æ¨¡å‹ã€‚

### 3. æŒ‡ä»¤å¾®è°ƒ

```bash
python gpt_instruction_finetuning.py \
    --data instruction-data.json \
    --epochs 3 \
    --batch_size 4 \
    --lr 5e-5
```

### 4. è¯„ä¼°å’Œæ¨ç†

```bash
# è¯„ä¼°æ¨¡å‹
python evaluate_model.py

# äº¤äº’å¼æµ‹è¯•
python fine-tuning.py --interactive
```

---

## ğŸ—ï¸ æŒ‡ä»¤å¾®è°ƒæ¶æ„

```
User Instruction + Input
    â†“
"### Instruction:\n{instruction}\n\n### Input:\n{input}\n\n### Response:\n"
    â†“
GPT-2 Model (å¾®è°ƒ)
    â†“
Generated Response
    â†“
"### Response:\n{output}"
```

---

## ğŸ“š æ ¸å¿ƒæ¦‚å¿µ

### æŒ‡ä»¤å¾®è°ƒ vs é¢„è®­ç»ƒ

| æ–¹é¢ | é¢„è®­ç»ƒ | æŒ‡ä»¤å¾®è°ƒ |
|------|--------|---------|
| **ç›®æ ‡** | å­¦ä¹ è¯­è¨€æ¨¡å¼ | å­¦ä¹ éµå¾ªæŒ‡ä»¤ |
| **æ•°æ®** | æ— æ ‡æ³¨æ–‡æœ¬ | æŒ‡ä»¤-å“åº”å¯¹ |
| **ä»»åŠ¡** | ä¸‹ä¸€ä¸ªè¯é¢„æµ‹ | æ¡ä»¶ç”Ÿæˆ |
| **èƒ½åŠ›** | é€šç”¨è¯­è¨€ç†è§£ | ç‰¹å®šä»»åŠ¡æ‰§è¡Œ |

### æ•°æ®æ ¼å¼è®¾è®¡

**Alpaca æ ¼å¼** (æ¨è):
```
### Instruction:
{instruction}

### Input:
{input}

### Response:
{output}
```

**ä¼˜åŠ¿**:
- æ˜ç¡®çš„ç»“æ„åŒ–æ ‡è®°
- æ¨¡å‹æ˜“äºè¯†åˆ«å„éƒ¨åˆ†
- æ”¯æŒæœ‰/æ— è¾“å…¥çš„æŒ‡ä»¤

### è®­ç»ƒç›®æ ‡

åªè®¡ç®— Response éƒ¨åˆ†çš„æŸå¤±ï¼š

```python
# åˆ›å»ºæŸå¤±æ©ç 
loss_mask = torch.zeros_like(input_ids)
response_start_idx = find_response_start(input_ids)
loss_mask[:, response_start_idx:] = 1

# è®¡ç®—æŸå¤±
loss = criterion(logits, targets) * loss_mask
loss = loss.sum() / loss_mask.sum()
```

---

## ğŸ’¡ å®Œæ•´å¾®è°ƒæµç¨‹

```python
from gpt_instruction_finetuning import InstructionGPT
from create_data_loaders import create_instruction_dataloader

# åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
model = load_gpt2_medium()

# åˆ›å»ºæŒ‡ä»¤å¾®è°ƒåŒ…è£…
instruction_model = InstructionGPT(model)

# å‡†å¤‡æ•°æ®
train_loader = create_instruction_dataloader(
    'instruction-data.json',
    batch_size=4,
    max_length=512
)

# ä¼˜åŒ–å™¨
optimizer = torch.optim.AdamW(
    model.parameters(),
    lr=5e-5,
    weight_decay=0.01
)

# è®­ç»ƒå¾ªç¯
for epoch in range(3):
    for batch in train_loader:
        # å‰å‘ä¼ æ’­
        logits = model(batch['input_ids'])
        
        # åªè®¡ç®— response éƒ¨åˆ†æŸå¤±
        loss = compute_instruction_loss(
            logits, 
            batch['labels'],
            batch['response_mask']
        )
        
        # åå‘ä¼ æ’­
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        print(f"Loss: {loss.item():.4f}")

# ä¿å­˜å¾®è°ƒæ¨¡å‹
torch.save(model.state_dict(), 'gpt2-medium355M-sft.pth')
```

---

## ğŸ¯ æŒ‡ä»¤ç±»å‹ç¤ºä¾‹

### 1. æ–‡æœ¬ç”Ÿæˆ
```
Instruction: å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„è¯—
Input: 
Output: æ˜¥é£æ‹‚é¢æš–é˜³å¤©ï¼Œ...
```

### 2. é—®ç­”
```
Instruction: å›ç­”ä»¥ä¸‹é—®é¢˜
Input: åœ°çƒä¸Šæœ€é«˜çš„å±±æ˜¯ä»€ä¹ˆï¼Ÿ
Output: ç ç©†æœ—ç›å³°ï¼Œæµ·æ‹” 8,848.86 ç±³ã€‚
```

### 3. æ–‡æœ¬è½¬æ¢
```
Instruction: å°†ä»¥ä¸‹å¥å­æ”¹å†™ä¸ºæ­£å¼è¯­æ°”
Input: è¿™ä¸œè¥¿çœŸçš„è¶…çº§å¥½ç”¨ï¼
Output: è¯¥äº§å“å…·æœ‰ä¼˜å¼‚çš„æ€§èƒ½å’Œå®ç”¨ä»·å€¼ã€‚
```

### 4. åˆ†ç±»
```
Instruction: åˆ¤æ–­ä»¥ä¸‹è¯„è®ºçš„æƒ…æ„Ÿå€¾å‘ï¼ˆæ­£é¢/è´Ÿé¢ï¼‰
Input: è¿™éƒ¨ç”µå½±å¤ªç²¾å½©äº†ï¼
Output: æ­£é¢
```

### 5. æ‘˜è¦
```
Instruction: æ€»ç»“ä»¥ä¸‹æ–‡ç« çš„ä¸»è¦å†…å®¹
Input: [é•¿æ–‡æœ¬]
Output: æœ¬æ–‡ä¸»è¦è®¨è®ºäº†...
```

---

## ğŸ“Š è¯„ä¼°æ–¹æ³•

### 1. è‡ªåŠ¨è¯„ä¼°

```python
from evaluate_model import evaluate_instructions

metrics = evaluate_instructions(
    model,
    test_data='test_instructions.json'
)

print(f"ROUGE-L: {metrics['rouge_l']:.2f}")
print(f"BLEU: {metrics['bleu']:.2f}")
print(f"Exact Match: {metrics['exact_match']:.2%}")
```

### 2. äººå·¥è¯„ä¼°

è¯„ä¼°ç»´åº¦:
- âœ… **ç›¸å…³æ€§**: å“åº”æ˜¯å¦å›ç­”äº†æŒ‡ä»¤
- âœ… **å‡†ç¡®æ€§**: ä¿¡æ¯æ˜¯å¦æ­£ç¡®
- âœ… **æµç•…æ€§**: è¯­è¨€æ˜¯å¦è‡ªç„¶
- âœ… **å®Œæ•´æ€§**: æ˜¯å¦å®Œæ•´å›ç­”

### 3. å¯¹æ¯”æµ‹è¯•

```bash
python evaluate_model.py --compare
```

å¯¹æ¯”å¾®è°ƒå‰åçš„å“åº”è´¨é‡ã€‚

---

## ğŸ” æ¨ç†ç¤ºä¾‹

```python
from extract_response import generate_instruction_response

# åŠ è½½å¾®è°ƒæ¨¡å‹
model = load_instruction_model('gpt2-medium355M-sft.pth')

# æ„é€ æç¤º
instruction = "å°†ä»¥ä¸‹æ–‡æœ¬ç¿»è¯‘æˆè‹±è¯­"
input_text = "ä½ å¥½ï¼Œä¸–ç•Œï¼"

# ç”Ÿæˆå“åº”
response = generate_instruction_response(
    model,
    instruction=instruction,
    input_text=input_text,
    max_tokens=50,
    temperature=0.7
)

print(f"Instruction: {instruction}")
print(f"Input: {input_text}")
print(f"Response: {response}")
# Output: "Hello, World!"
```

---

## ğŸ¯ æç¤ºå·¥ç¨‹æŠ€å·§

### 1. æ¸…æ™°å…·ä½“çš„æŒ‡ä»¤
âŒ "å¤„ç†è¿™ä¸ªæ–‡æœ¬"
âœ… "å°†ä»¥ä¸‹æ–‡æœ¬ç¿»è¯‘æˆæ³•è¯­"

### 2. æä¾›ç¤ºä¾‹ (Few-Shot)
```
Instruction: å°†å¥å­æ”¹ä¸ºç–‘é—®å¥

Example 1:
Input: ä»–å–œæ¬¢ç¯®çƒã€‚
Output: ä»–å–œæ¬¢ç¯®çƒå—ï¼Ÿ

Example 2:
Input: [å®é™…è¾“å…¥]
Output:
```

### 3. åˆ†æ­¥éª¤æŒ‡ä»¤
```
Instruction: 
1. é˜…è¯»ä»¥ä¸‹æ–‡æœ¬
2. æå–å…³é”®ä¿¡æ¯
3. ç”¨ä¸‰å¥è¯æ€»ç»“
```

### 4. æŒ‡å®šè¾“å‡ºæ ¼å¼
```
Instruction: ä»¥ JSON æ ¼å¼æå–ä»¥ä¸‹ä¿¡æ¯ï¼š
- å§“å
- å¹´é¾„
- èŒä¸š
```

---

## ğŸ”§ é«˜çº§æŠ€æœ¯

### 1. RLHF (äººç±»åé¦ˆå¼ºåŒ–å­¦ä¹ )
ä¸‹ä¸€æ­¥å¯ä»¥ä½¿ç”¨äººç±»åé¦ˆè¿›ä¸€æ­¥ä¼˜åŒ–ã€‚

### 2. LoRA (ä½ç§©é€‚åº”)
ä»…å¾®è°ƒéƒ¨åˆ†å‚æ•°ï¼Œå‡å°‘è®¡ç®—å’Œå­˜å‚¨ã€‚

### 3. Prompt Tuning
åªä¼˜åŒ–æç¤ºè¯åµŒå…¥ï¼Œå†»ç»“æ¨¡å‹å‚æ•°ã€‚

---

## ğŸ“– æ•°æ®é›†èµ„æº

å…¬å¼€çš„æŒ‡ä»¤æ•°æ®é›†:
- **Alpaca**: 52K æŒ‡ä»¤-å“åº”å¯¹
- **Dolly**: 15K é«˜è´¨é‡æ ·æœ¬
- **FLAN**: å¤šä»»åŠ¡æŒ‡ä»¤é›†åˆ
- **Self-Instruct**: è‡ªåŠ¨ç”ŸæˆæŒ‡ä»¤

---

## ğŸ”— ç›¸å…³ç« èŠ‚

- **ä¸Šä¸€ç« **: [Chapter 6 - åˆ†ç±»ä»»åŠ¡å¾®è°ƒ](../chap6-fine-tuning-for-classification/)
- **é™„å½•**: é«˜çº§è®­ç»ƒæŠ€æœ¯

---

**æœ€åæ›´æ–°**: 2025å¹´11æœˆ17æ—¥
