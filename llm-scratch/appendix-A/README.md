# Appendix A: åˆ†å¸ƒå¼æ•°æ®å¹¶è¡Œè®­ç»ƒ

æœ¬é™„å½•ä»‹ç»å¦‚ä½•ä½¿ç”¨ PyTorch çš„åˆ†å¸ƒå¼æ•°æ®å¹¶è¡Œ (DDP) æ¥åŠ é€Ÿå¤§æ¨¡å‹è®­ç»ƒã€‚

---

## ğŸ“‚ æ–‡ä»¶è¯´æ˜

```
appendix-A/
â”œâ”€â”€ DDP-script.py              # åŸºç¡€ DDP è®­ç»ƒè„šæœ¬
â””â”€â”€ DDP-script-torchrun.py     # ä½¿ç”¨ torchrun çš„ DDP è„šæœ¬
```

---

## ğŸ¯ å­¦ä¹ ç›®æ ‡

- âœ… ç†è§£åˆ†å¸ƒå¼è®­ç»ƒåŸç†
- âœ… æŒæ¡ DDP (DistributedDataParallel) ä½¿ç”¨
- âœ… å­¦ä¹ å¤š GPU è®­ç»ƒé…ç½®
- âœ… ä¼˜åŒ–è®­ç»ƒæ•ˆç‡

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å•æœºå¤š GPU è®­ç»ƒ

#### æ–¹å¼ 1: ä½¿ç”¨ torch.distributed.launch (æ—§ç‰ˆ)

```bash
python -m torch.distributed.launch \
    --nproc_per_node=4 \
    DDP-script.py
```

#### æ–¹å¼ 2: ä½¿ç”¨ torchrun (æ¨è)

```bash
torchrun \
    --standalone \
    --nproc_per_node=4 \
    DDP-script-torchrun.py
```

### å¤šæœºå¤š GPU è®­ç»ƒ

```bash
# ä¸»èŠ‚ç‚¹ (rank 0)
torchrun \
    --nproc_per_node=4 \
    --nnodes=2 \
    --node_rank=0 \
    --master_addr="192.168.1.1" \
    --master_port=29500 \
    DDP-script-torchrun.py

# å·¥ä½œèŠ‚ç‚¹ (rank 1)
torchrun \
    --nproc_per_node=4 \
    --nnodes=2 \
    --node_rank=1 \
    --master_addr="192.168.1.1" \
    --master_port=29500 \
    DDP-script-torchrun.py
```

---

## ğŸ“š æ ¸å¿ƒæ¦‚å¿µ

### DistributedDataParallel (DDP)

DDP é€šè¿‡æ•°æ®å¹¶è¡Œå®ç°æ¨¡å‹è®­ç»ƒåŠ é€Ÿï¼š
- æ¯ä¸ª GPU æŒæœ‰æ¨¡å‹çš„å®Œæ•´å‰¯æœ¬
- æ•°æ®åœ¨ GPU é—´åˆ†ç‰‡
- æ¢¯åº¦åœ¨åå‘ä¼ æ’­ååŒæ­¥

### ä¸ DataParallel çš„åŒºåˆ«

| ç‰¹æ€§ | DataParallel (DP) | DistributedDataParallel (DDP) |
|------|------------------|------------------------------|
| **å¤šæœºæ”¯æŒ** | âŒ å¦ | âœ… æ˜¯ |
| **æ•ˆç‡** | è¾ƒä½ (å•è¿›ç¨‹) | é«˜ (å¤šè¿›ç¨‹) |
| **æ¢¯åº¦åŒæ­¥** | ä¸» GPU æ”¶é›† | All-Reduce |
| **æ¨è** | âŒ ä¸æ¨è | âœ… æ¨è |

---

## ğŸ’¡ DDP ä»£ç ç¤ºä¾‹

```python
import torch
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP

def setup(rank, world_size):
    """åˆå§‹åŒ–è¿›ç¨‹ç»„"""
    dist.init_process_group("nccl", rank=rank, world_size=world_size)
    torch.cuda.set_device(rank)

def cleanup():
    """æ¸…ç†è¿›ç¨‹ç»„"""
    dist.destroy_process_group()

def train(rank, world_size):
    # åˆå§‹åŒ–
    setup(rank, world_size)
    
    # åˆ›å»ºæ¨¡å‹å¹¶ç§»åˆ°å¯¹åº” GPU
    model = GPTModel(config).to(rank)
    model = DDP(model, device_ids=[rank])
    
    # åˆ›å»ºåˆ†å¸ƒå¼é‡‡æ ·å™¨
    sampler = DistributedSampler(
        dataset,
        num_replicas=world_size,
        rank=rank,
        shuffle=True
    )
    
    dataloader = DataLoader(
        dataset,
        batch_size=32,
        sampler=sampler
    )
    
    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)
    
    # è®­ç»ƒå¾ªç¯
    for epoch in range(num_epochs):
        sampler.set_epoch(epoch)  # é‡è¦ï¼ç¡®ä¿æ¯ä¸ª epoch æ•°æ®ä¸åŒ
        
        for batch in dataloader:
            batch = batch.to(rank)
            
            # å‰å‘ä¼ æ’­
            loss = model(batch)
            
            # åå‘ä¼ æ’­ï¼ˆè‡ªåŠ¨åŒæ­¥æ¢¯åº¦ï¼‰
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            
            if rank == 0:  # åªåœ¨ä¸»è¿›ç¨‹æ‰“å°
                print(f"Epoch {epoch}, Loss: {loss.item()}")
    
    # æ¸…ç†
    cleanup()

if __name__ == "__main__":
    world_size = torch.cuda.device_count()
    torch.multiprocessing.spawn(
        train,
        args=(world_size,),
        nprocs=world_size,
        join=True
    )
```

---

## ğŸ”§ å…³é”®é…ç½®

### ç¯å¢ƒå˜é‡

```bash
export MASTER_ADDR=localhost
export MASTER_PORT=29500
export WORLD_SIZE=4
export RANK=0
```

### è¿›ç¨‹ç»„åˆå§‹åŒ–

```python
# NCCL backend (æ¨èç”¨äº GPU)
dist.init_process_group(
    backend='nccl',
    init_method='env://',
    world_size=world_size,
    rank=rank
)

# Gloo backend (CPU æˆ–è·¨å¹³å°)
dist.init_process_group(
    backend='gloo',
    init_method='env://',
    world_size=world_size,
    rank=rank
)
```

---

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

### 1. Gradient Accumulation

```python
accumulation_steps = 4

for i, batch in enumerate(dataloader):
    loss = model(batch) / accumulation_steps
    loss.backward()
    
    if (i + 1) % accumulation_steps == 0:
        optimizer.step()
        optimizer.zero_grad()
```

### 2. Mixed Precision Training

```python
from torch.cuda.amp import autocast, GradScaler

scaler = GradScaler()

for batch in dataloader:
    with autocast():
        loss = model(batch)
    
    scaler.scale(loss).backward()
    scaler.step(optimizer)
    scaler.update()
    optimizer.zero_grad()
```

### 3. æ¢¯åº¦è£å‰ª

```python
torch.nn.utils.clip_grad_norm_(
    model.parameters(),
    max_norm=1.0
)
```

---

## ğŸ¯ æœ€ä½³å®è·µ

1. **ä½¿ç”¨ torchrun**: æ¯”æ—§ç‰ˆ launch æ›´ç¨³å®š
2. **NCCL backend**: GPU è®­ç»ƒé¦–é€‰
3. **è®¾ç½®éšæœºç§å­**: ç¡®ä¿å¯å¤ç°æ€§
4. **åˆç†æ‰¹æ¬¡å¤§å°**: `total_batch = per_gpu_batch Ã— num_gpus`
5. **ä¸»è¿›ç¨‹æ“ä½œ**: ä¿å­˜æ¨¡å‹ã€æ—¥å¿—ç­‰åªåœ¨ rank 0 æ‰§è¡Œ

---

## ğŸ”— ç›¸å…³èµ„æº

- [PyTorch DDP å®˜æ–¹æ•™ç¨‹](https://pytorch.org/tutorials/intermediate/ddp_tutorial.html)
- [NCCL æ–‡æ¡£](https://docs.nvidia.com/deeplearning/nccl/)

---

**æœ€åæ›´æ–°**: 2025å¹´11æœˆ17æ—¥
