"""
Hugging Face Transformers å®Œæ•´ä½¿ç”¨ç¤ºä¾‹
åŒ…å«å¤šç§å¸¸è§NLPä»»åŠ¡çš„å®ç°
"""

from transformers import pipeline
import warnings
warnings.filterwarnings('ignore')

print("ğŸ¤— Hugging Face Transformers ç¤ºä¾‹é›†åˆ\n")

# ==================== 1. æ–‡æœ¬ç”Ÿæˆ ====================
print("=" * 60)
print("1ï¸âƒ£ æ–‡æœ¬ç”Ÿæˆ (Text Generation)")
print("=" * 60)

generator = pipeline('text-generation', model='gpt2')
prompt = "The future of artificial intelligence is"
result = generator(
    prompt,
    max_length=80,
    num_return_sequences=2,
    temperature=0.8
)

for i, gen in enumerate(result, 1):
    print(f"\nç”Ÿæˆ {i}:")
    print(gen['generated_text'])

# ==================== 2. æƒ…æ„Ÿåˆ†æ ====================
print("\n" + "=" * 60)
print("2ï¸âƒ£ æƒ…æ„Ÿåˆ†æ (Sentiment Analysis)")
print("=" * 60)

sentiment = pipeline('sentiment-analysis')
texts = [
    "I love this product! It's amazing!",
    "This is terrible, worst experience ever.",
    "It's okay, nothing special."
]

for text in texts:
    result = sentiment(text)[0]
    print(f"\næ–‡æœ¬: {text}")
    print(f"æƒ…æ„Ÿ: {result['label']} (ç½®ä¿¡åº¦: {result['score']:.2%})")

# ==================== 3. é—®ç­”ç³»ç»Ÿ ====================
print("\n" + "=" * 60)
print("3ï¸âƒ£ é—®ç­”ç³»ç»Ÿ (Question Answering)")
print("=" * 60)

qa = pipeline('question-answering')
context = """
Hugging Face is a company that develops tools for building applications using 
machine learning. It is most notable for its Transformers library built for 
natural language processing applications and its platform that allows users to 
share machine learning models and datasets.
"""

questions = [
    "What is Hugging Face?",
    "What is the Transformers library used for?",
]

for question in questions:
    result = qa(question=question, context=context)
    print(f"\né—®é¢˜: {question}")
    print(f"ç­”æ¡ˆ: {result['answer']}")
    print(f"ç½®ä¿¡åº¦: {result['score']:.2%}")

# ==================== 4. æ–‡æœ¬æ‘˜è¦ ====================
print("\n" + "=" * 60)
print("4ï¸âƒ£ æ–‡æœ¬æ‘˜è¦ (Summarization)")
print("=" * 60)

summarizer = pipeline('summarization', model='facebook/bart-large-cnn')
article = """
The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey 
building, and the tallest structure in Paris. Its base is square, measuring 
125 metres (410 ft) on each side. During its construction, the Eiffel Tower 
surpassed the Washington Monument to become the tallest man-made structure in 
the world, a title it held for 41 years until the Chrysler Building in New York 
City was finished in 1930.
"""

summary = summarizer(article, max_length=50, min_length=25, do_sample=False)
print(f"\nåŸæ–‡: {article[:100]}...")
print(f"\næ‘˜è¦: {summary[0]['summary_text']}")

# ==================== 5. å‘½åå®ä½“è¯†åˆ« ====================
print("\n" + "=" * 60)
print("5ï¸âƒ£ å‘½åå®ä½“è¯†åˆ« (Named Entity Recognition)")
print("=" * 60)

ner = pipeline('ner', grouped_entities=True)
text = "Apple Inc. was founded by Steve Jobs in Cupertino, California."

entities = ner(text)
print(f"\næ–‡æœ¬: {text}\n")
print("è¯†åˆ«çš„å®ä½“:")
for entity in entities:
    print(f"  - {entity['word']}: {entity['entity_group']} (ç½®ä¿¡åº¦: {entity['score']:.2%})")

# ==================== 6. ç¿»è¯‘ ====================
print("\n" + "=" * 60)
print("6ï¸âƒ£ ç¿»è¯‘ (Translation)")
print("=" * 60)

# è‹±è¯‘æ³•
en_to_fr = pipeline('translation_en_to_fr', model='t5-small')
en_text = "Hello, how are you today?"
fr_result = en_to_fr(en_text)
print(f"\nè‹±è¯­ â†’ æ³•è¯­:")
print(f"  åŸæ–‡: {en_text}")
print(f"  è¯‘æ–‡: {fr_result[0]['translation_text']}")

# ==================== 7. é›¶æ ·æœ¬åˆ†ç±» ====================
print("\n" + "=" * 60)
print("7ï¸âƒ£ é›¶æ ·æœ¬åˆ†ç±» (Zero-Shot Classification)")
print("=" * 60)

classifier = pipeline('zero-shot-classification')
text = "This is a tutorial about using transformers for NLP tasks."
candidate_labels = ['education', 'politics', 'sports', 'technology']

result = classifier(text, candidate_labels)
print(f"\næ–‡æœ¬: {text}\n")
print("åˆ†ç±»ç»“æœ:")
for label, score in zip(result['labels'], result['scores']):
    print(f"  {label}: {score:.2%}")

# ==================== 8. å¡«å……é®ç½©è¯ ====================
print("\n" + "=" * 60)
print("8ï¸âƒ£ å¡«å……é®ç½©è¯ (Fill-Mask)")
print("=" * 60)

fill_mask = pipeline('fill-mask')
text = "Artificial intelligence will <mask> the future of technology."

results = fill_mask(text, top_k=3)
print(f"\nå¥å­: {text}\n")
print("å¯èƒ½çš„å¡«å……:")
for i, result in enumerate(results, 1):
    print(f"  {i}. {result['token_str']}: {result['score']:.2%}")

print("\n" + "=" * 60)
print("âœ… æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆï¼")
print("=" * 60)

print("\nğŸ’¡ æç¤º:")
print("  - é¦–æ¬¡è¿è¡Œä¼šä¸‹è½½æ¨¡å‹ï¼Œéœ€è¦ä¸€äº›æ—¶é—´")
print("  - æ¨¡å‹ç¼“å­˜åœ¨ ~/.cache/huggingface/")
print("  - æ‚¨çš„Macæ”¯æŒMPSåŠ é€Ÿï¼Œè®­ç»ƒä¼šå¾ˆå¿«ï¼")
print("  - æ›´å¤šæ¨¡å‹è¯·è®¿é—®: https://huggingface.co/models")
